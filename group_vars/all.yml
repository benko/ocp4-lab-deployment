---
# These are the global settings for the cluster deployment.
#
# OpenShift Cluster configuration.
#
# Some suggestions on where to put things:
#  - binary artifacts path (easier .gitignore - MAKE IT A RELATIVE PATH!)
binary_artifact_path: binaries/

#  - the cluster state directory (same here - MAKE IT A RELATIVE PATH!)
openshift_rtdata_path: cluster/

#  - the installer and client binaries
openshift_installer_path: "{{ binary_artifact_path }}/openshift-install"
oc_bin: "{{ binary_artifact_path }}/oc"

#  - the RHEL ISO image to use (all expected in binary_artifact_path)
rhel8_artifacts:
  - rhel-8.0-x86_64-dvd.iso

#  - the RHEL CoreOS release and artifacts (same, binary_artifact_path)
#     NOTE: use the following image names prior to 4.3.0:
#           coreos_release: 4.2.0-x86_64
#           coreos_arch: x86_64
#           coreos_http_artifacts:
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-metal-bios.raw.gz
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-metal-uefi.raw.gz
#           coreos_tftp_artifacts:
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-installer-kernel
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-installer-initramfs.img
#     NOTE: use the following image names for 4.3.0:
#           coreos_release: 4.3.0-x86_64
#           coreos_arch: x86_64
#           coreos_http_artifacts:
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-metal.raw.gz
#           coreos_tftp_artifacts:
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-installer-kernel
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-installer-initramfs.img
#     NOTE: use the following image names between 4.3.8 and 4.6.0:
#           coreos_release: 4.3.8
#           coreos_arch: x86_64
#           coreos_http_artifacts:
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-metal.{{ coreos_arch }}.raw.gz
#           coreos_tftp_artifacts:
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-installer-kernel-{{ coreos_arch }}
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-installer-initramfs.{{ coreos_arch }}.img
#     NOTE: use the following image names for 4.6.1 and newer:
#           coreos_release: 4.6.1
#           coreos_arch: x86_64
#           coreos_http_artifacts:
#             - rhcos-{{ coreos_release }}-{{ coreos_arch }}-metal.{{ coreos_arch }}.raw.gz
#           coreos_tftp_artifacts:
#             - rhcos-{{ coreos_release }}-live-kernel-{{ coreos_arch }}
#             - rhcos-{{ coreos_release }}-live-initramfs.{{ coreos_arch }}.img
coreos_release: 4.6.1
coreos_arch: x86_64
coreos_http_artifacts:
  - rhcos-{{ coreos_release }}-{{ coreos_arch }}-metal.{{ coreos_arch }}.raw.gz
coreos_tftp_artifacts:
  - rhcos-{{ coreos_release }}-{{ coreos_arch }}-live-kernel-{{ coreos_arch }}
  - rhcos-{{ coreos_release }}-{{ coreos_arch }}-live-initramfs.{{ coreos_arch }}.img

# Other package versions - these are also expected in binary_artifact_path.
# OpenVPN and PKCS11 helper are optional, skip with --skip-tags=openvpn
# (both are from https://epel.ip-connect.info/8/Everything/x86_64/Packages/)
nexus_release: 3.19.1-01
openvpn_release: 2.4.7-1
pkcs11_release: 1.22-7

# A chance OpenVPN setting: normally we'll run without DH params, which
# enforces ECDS. If your client can't speak it, you should really update to a
# newer OpenSSL library. But in the mean time, set this to "yes".
ovpn_enforce_dhparam: no

# DNS settings. "cluster_name" becomes a subdomain of "parent_domain".
# All the virtual machines (except services) are provisioned in the cluster
# domain. services VM is provisioned in parent domain.
parent_domain: lab.example.com
cluster_name: ocp

# The forwarding DNS server to configure services VM with.
fwd_dns_server: 172.25.254.254

# Similarly, the (actual) default gateway for the services VM.
svc_default_gw: 172.25.254.252

# Since we're talking about addressing, let's also set the MAC address and IP
# subnet prefix here. Free for you to change, of course.
ip_prefix: 172.25.250
mac_prefix: 52:54:00:00:fa

# Still in networking. If there is bridged network, say so and tell which
# interface. Otherwise tell which virt net to use.
vm_use_bridge: yes
vm_bridge_name: privbr0
vm_network_name: ignored-if-use-bridge

# Services VM. Even if using a bridge, there might be a need to create a second
# interface and connect it to a bridge, as the primary interface bridge may be
# to a non-reachable network.
#
# NOTE: At any rate, regardless of what you decide here, it is your
#       responsibility to make sure all the VMs resolve correctly from the
#       point where services VM is up and running.
#
# NOTE: Only do this in environments where you intend to only run one cluster,
#       otherwise you will have a pretty nice mess on your hands thanks to IP
#       conflicts.
vm_svc_add_interface: yes
vm_svc_add_bridge_name: br0
vm_svc_add_macaddr: "{{ mac_prefix }}:f1"
vm_svc_add_ipaddr: 172.25.254.21
vm_svc_add_netmask: 255.255.255.0

# The deployed image URLs. These will depend on the version of OpenShift
# installer you use, but should be OK for nightly builds. What they mostly
# affect is just what image URLs the installer will use Nexus for.
ocp_release_image: openshift-release-dev/ocp-release
ocp_worker_image: openshift-release-dev/ocp-v4.0-art-dev

# Any additional content that should be mirrored in the Nexus repo.  Do note
# that the only two proxy repositories defined as of now are quay.io and
# registry.redhat.io. If your mirrored images are coming from somewhere else,
# you will need to add a new proxy repository to Nexus configuration (and
# modify the group repo on port 5000).
additional_content_sources:
  - registry_host: registry.redhat.io
    image_basename: rhel8/postgresql-96
  - registry_host: registry.redhat.io
    image_basename: rhscl/mysql-57-rhel7
  - registry_host: registry.redhat.io
    image_basename: redhat-openjdk-18/openjdk18-openshift

# NFS server exports for PersistentVolume provisioning. The important bit is
# that the registry PV is at least 100Gi. Create as many as you want here, the
# playbooks will create both the directories on NFS server (and export them)
# and provision the PVs at a later point.
nfs_parent: /var/exports
nfs_exports:
  - name: registry
    capacity: 100Gi
  - name: vol01
    capacity: 1Gi
  - name: vol02
    capacity: 3Gi
  - name: vol03
    capacity: 5Gi
  - name: vol04
    capacity: 10Gi
  - name: vol05
    capacity: 15Gi

# We create a certificate authority as part of the installation. These are the
# related settings. The reason validity is an absolute date is because with a
# relative date, all cert-related operations become non-idempotent.
#
# NOTE: All generated certificates will use this expiration date.
x509_ca_location: /var/www/html/ca
x509_ca_pass: veryverysecret
x509_validity_until: '20291011000000Z'

# Nexus Repository Manager v3 certificate settings.
nexus_key_alias: nexus
nexus_keystore_pass: anotherverysecret

# The VM catalog.
vms:
  # The default settings that VMs can override (resolved at play level).
  # These (obviously) do not provide hostname, mac, and ipaddr.
  global:
    netmask: 255.255.255.0      # changing this will make your life miserable
    dns: "{{ ip_prefix }}.21"   # use services VM - XXX DO NOT CHANGE THIS! XXX
    tz: Europe/Tallinn
    mem_gb: 6
    ncpus: 4
    # Unfortunately we need the gateway for airgap install, because NM refuses
    # to set the hostname if it has no interfaces with default gateway. In
    # other words, the only way to set a hostname for a VM using DHCP is to
    # have at least one interface with a default gateway. We'll make it a bogus
    # one, of course - no other VM except the services one needs internet
    # access, and even that one only the first time around.
    # Alternatively, you can of course set this to svc_default_gw and have your
    # cluster register itself in RH Cloud Manager, and/or use online registries.
    #
    # NOTE: You might *have to* set this to the services VM with libvirt
    #       networking and OpenVPN, if you want to be able to access the
    #       cluster nodes.
    # NOTE: If you change any of these for the RHCOS VMs *after* the services
    #       VM has been provisioned, you will have to regenerate (or otherwise
    #       fix) the DHCP server configuration.
    #gw: "{{ ip_prefix }}.199"
    gw: "{{ ip_prefix }}.21"
  services:
    hostname: services.{{ parent_domain }}
    mac: "{{ mac_prefix }}:21"
    ipaddr: "{{ ip_prefix }}.21"
    dns: "{{ fwd_dns_server }}" # this will eventually become the forwarder
    gw: "{{ svc_default_gw }}"  # this is an actual valid default gateway
    mem_gb: 3
    ncpus: 2
  bootstrap:
    hostname: bootstrap.{{ cluster_name }}.{{ parent_domain }}
    mac: "{{ mac_prefix }}:31"
    ipaddr: "{{ ip_prefix }}.31"
    mem_gb: 4
  master:
    hostname: master.{{ cluster_name }}.{{ parent_domain }}
    mac: "{{ mac_prefix }}:40"
    ipaddr: "{{ ip_prefix }}.40"
    mem_gb: 8
  worker1:
    hostname: worker1.{{ cluster_name }}.{{ parent_domain }}
    mac: "{{ mac_prefix }}:41"
    ipaddr: "{{ ip_prefix }}.41"
  worker2:
    hostname: worker2.{{ cluster_name }}.{{ parent_domain }}
    mac: "{{ mac_prefix }}:42"
    ipaddr: "{{ ip_prefix }}.42"

# This user will be created in all RHEL VMs (which is basically, services).
# By default, this user's password is "student". The SSH public key though,
# will be published in *all* VMs, including RHEL CoreOS. The target user to
# access those systems is "core".
auth_user_username: student
auth_user_fullname: Student User
auth_user_password: $6$8oIjLCsc$/n1iQXYh1E6.uOEuJKgioqAtmqm2TQmkJGF2RwyteIr1tIfrPdiRYgWe6Sjen5/eMij2uHM/a1tue/QRlo3X80
auth_user_publickey: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDGtUW3ismHyuCW4CDdTVOOOq6aySdtYenXFWWx7HJa4VTepkG00aaLId9ocra10hc+MB0GTJMCyabDv3i8NKdi6GDH/aOLVsp/Ewy8DEzZMBlJDCt4v2i4/wU4liw6KgEFkZs+5hnqU8d4QzldyGJ5onr+AGvFOKG68CS0BBl40Z1twf1HhCyx8k6nzD2ovlkxWRFZKPAFrtPCBVvQDkOfVFZF+lwzaSztgAjbFZ4A9jqQyUYx4kOJ5DtRef36ucdUdVQale0+8lICl7/gb142SPpYfhxe88/BJScLPRjvVNeu1TxRmoHtVazqnAoRxQYAn2MoI6AG+w6QuZf8f7aL LabGradingKey

# This sample root password says "redhat".
rhel_root_password: $6$IfN//lIj$k6Ui76Hy2W051b4XzMmWnqrUtatCBK7N.WwOpu5SE1X6uqko2RyYvkMJTBK7cEFiTUHLZSs3SLbLZSGglMd8F1

# Authentication-related information.
# NOTE: THIS IS ALL BOGUS DATA SO DO NOT USE IT. IT WILL NOT WORK!
#
# Do the needful, as they say, and get yourself an actual pull secret from
# try.openshift.com - you just need a (free) Red Hat account for that, and
# you'll need it to download the installer and the client anyway.
auth_user_pullsecret: '{"auths":{"cloud.openshift.com":{"auth":"b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K2VpcGhhaTFzaGFoc2g0RWVwaGFlZ2hlZXNhaDBhaWc3dGhvS2FpbmdhOGNoZTB2aTk6RUVZM0FJUVVFSTVJTkdJRVoyVEhVVjlPSEJJMUdFRVlFSVJVRkVJVzZMQUhORzNDSEVBUjFBRUZVRkVFNVNPSA==","email":"student@example.com"},"quay.io":{"auth":"b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K2VpcGhhaTFzaGFoc2g0RWVwaGFlZ2hlZXNhaDBhaWc3dGhvS2FpbmdhOGNoZTB2aTk6RUVZM0FJUVVFSTVJTkdJRVoyVEhVVjlPSEJJMUdFRVlFSVJVRkVJVzZMQUhORzNDSEVBUjFBRUZVRkVFNVNPSA==","email":"student@example.com"},"registry.connect.redhat.com":{"auth":"MzQ1NjcyM3x1aGMtcGhhNWFld2lvUGg3TG9vcmU5amVpdG9oNm9oOmV5SmhiR2NpT2lKU1V6VXhNaUo5LmV5SnpkV0lpT2lJMVpEVTROVEl5TkdGaFlXUTBNV0l3T1dJeU1qVTFNamhtWXpKbVlqbGpNU0o5LnVXb2hvaEQzbm9veGlldzZiYTR1Q2hlZXRodTdzaHUyZWVQaDBob28xY2FpUjBlZW0wZWlTaDNnYWVMaThDaGFlOWFldzdkZWl5ZWlnM2lldmllYm9oUHV5MGJpZWwzZGFpcmVpMm9TaDBlaXNoYWgxb3RoZW92b29naDhmb290aGE1a3VvcXVvM1Rob280cGU5VXN1d2VlbjVlaWxpa2VleTBlaWI0a2VpY2FpTmc1YXBpZWRhaXRlZWZpZThtdW8yZWVmdThlZXF1MXllaXJvYTFiYWkyYm9vUnVwOWlQZXAwQVRpdWxhaHF1dTRCb3VTaGFoOU5haHh1YWJhaFM0ZWVzaGFpM1R1OGFleDBsZWk5bW9vbmFpaGFlV2k3a2VlYmk3YXNoZTBxdWFoamllMHpvaHRoaXY0dmVpNG9qYXhvaHlhaVNoZXVzM2lvZ2g0ZWlzaDFjaG9vNnZhaTJ1dVBpZXBodXVtYWVnaDhvaGZlZWdhMW9pNWFlU29vNXNodVBob2gxdHVlcXVhaWphN2FuYWU2ZWRlbml0aGEydW5vTmdvb2NoZWk3U2hhZXNhdmFldGhlZXRob2h6OWVlbm9vNG9naGFlcGg3bm9oZm9pbGVlR2hhaWRvaGZhaWNoYWVtOHNoYTRwaGVhbG9vNEVQdWFjZXppajFkaWVLZWV4Nm9vU2FoNnF1aWJpVm9oeDdpZWY3bGllNGlyb29zb29naGE2aWVYYWVsdTZ0ZWl2aWVzaDJ1cXVhaU1haHc3VmllY2Vlc2hvb2c5aWVmNGFlWGllZmVpNGFlaDlhZWNoZWlxdW9vczRjYWVHaGVlbmdlZW5nZWVnaGFldDdBaHF1OXJvaHMxY2VlMmNob2F4dWoyY2hvejJvb2NvbzVhZWd1YWNpZXBv","email":"student@example.com"},"registry.redhat.io":{"auth":"MzQ1NjcyM3x1aGMtcGhhNWFld2lvUGg3TG9vcmU5amVpdG9oNm9oOmV5SmhiR2NpT2lKU1V6VXhNaUo5LmV5SnpkV0lpT2lJMVpEVTROVEl5TkdGaFlXUTBNV0l3T1dJeU1qVTFNamhtWXpKbVlqbGpNU0o5LnVXb2hvaEQzbm9veGlldzZiYTR1Q2hlZXRodTdzaHUyZWVQaDBob28xY2FpUjBlZW0wZWlTaDNnYWVMaThDaGFlOWFldzdkZWl5ZWlnM2lldmllYm9oUHV5MGJpZWwzZGFpcmVpMm9TaDBlaXNoYWgxb3RoZW92b29naDhmb290aGE1a3VvcXVvM1Rob280cGU5VXN1d2VlbjVlaWxpa2VleTBlaWI0a2VpY2FpTmc1YXBpZWRhaXRlZWZpZThtdW8yZWVmdThlZXF1MXllaXJvYTFiYWkyYm9vUnVwOWlQZXAwQVRpdWxhaHF1dTRCb3VTaGFoOU5haHh1YWJhaFM0ZWVzaGFpM1R1OGFleDBsZWk5bW9vbmFpaGFlV2k3a2VlYmk3YXNoZTBxdWFoamllMHpvaHRoaXY0dmVpNG9qYXhvaHlhaVNoZXVzM2lvZ2g0ZWlzaDFjaG9vNnZhaTJ1dVBpZXBodXVtYWVnaDhvaGZlZWdhMW9pNWFlU29vNXNodVBob2gxdHVlcXVhaWphN2FuYWU2ZWRlbml0aGEydW5vTmdvb2NoZWk3U2hhZXNhdmFldGhlZXRob2h6OWVlbm9vNG9naGFlcGg3bm9oZm9pbGVlR2hhaWRvaGZhaWNoYWVtOHNoYTRwaGVhbG9vNEVQdWFjZXppajFkaWVLZWV4Nm9vU2FoNnF1aWJpVm9oeDdpZWY3bGllNGlyb29zb29naGE2aWVYYWVsdTZ0ZWl2aWVzaDJ1cXVhaU1haHc3VmllY2Vlc2hvb2c5aWVmNGFlWGllZmVpNGFlaDlhZWNoZWlxdW9vczRjYWVHaGVlbmdlZW5nZWVnaGFldDdBaHF1OXJvaHMxY2VlMmNob2F4dWoyY2hvejJvb2NvbzVhZWd1YWNpZXBv","email":"student@example.com"}}}'
...
